# copybook-rs Roadmap

**Status:** âœ… Production Ready (v0.3.0)

This roadmap tracks **what we will ship**, **how we'll measure it**, and **when it's done**. Each milestone has: Objectives â†’ Deliverables â†’ Exit Criteria â†’ Risks/Mitigations.

---

## Principles (keep these stable)

* **Stability first**: No breaking public behaviors without a minor+ bump; hold API freeze before v1.0.
* **Performance budgeted**: Any change must keep â‰¥ **DISPLAY 4.1â€“4.2 GiB/s** and **COMP-3 560â€“580 MiB/s**, memory < **256 MiB** steady-state.
* **Single source of truth**: Performance figures live in **README "Performance Specifications"**; other docs reference it.
* **Determinism**: Parallel decode remains deterministic; round-trip remains lossless.

---

## Milestone v0.4.0 â€” Distribution & CI (October 2025)  ðŸš€ *current focus*

### Objectives

* Make installation trivial; make performance visible in PRs; lock structural semantics with fixtures.

### Deliverables

1. **âœ… Crates.io publish** (`core`, `codec`, `cli`) â€” **COMPLETED**

   * âœ… crate metadata: categories, keywords, readme path, license files included
   * âœ… workspace dependencies configured for version-based publishing
   * âœ… publish dry-run validation in CI
   * ðŸ”„ docs.rs builds for all crates (pending first publish)
2. **Bench receipts in CI** (#52) â€” **IN PROGRESS**

   * criterion JSON + rolled-up `perf.json` artifact
   * PR comment: SLO deltas and pass/fail against budgets (Â±5% warn, >10% fail)
   * Upload to GitHub Actions artifacts with 14-day retention
3. **Golden fixtures** (#53) â€” **PLANNED**

   * `level-88 after ODO` (pass) - validates deep nesting works
   * `child-inside-ODO` (pass) - validates inner field access
   * `storage sibling after ODO` (fail) - enforces structural constraints
4. **Docs nav + link hygiene** â€” **PLANNED**

   * Create `docs/CLI_REFERENCE.md` and `docs/LIBRARY_API.md`
   * Remove duplicate perf numbers elsewhere; link to canonical section
   * Add navigation to README with anchor links

### Exit Criteria (all must be true)

* `cargo publish` sequence completes successfully; `cargo add copybook-cli` works in clean project
* docs.rs pages build and are accessible for all three crates
* CI uploads bench artifacts and posts **bench summary** on PRs; SLO failures block merge
* Golden fixtures run in CI; the failing sibling-after-ODO case is properly asserted
* Documentation audit complete: no duplicate perf numbers, working anchor links

### Risks & Mitigations

* **docs.rs build timing out** â†’ slim examples; mark heavy benches as `#[cfg(docsrs)]`
* **Artifact bloat** â†’ limit to raw criterion JSON + â‰¤50KB rollup; 14-day retention
* **Publishing sequence failure** â†’ automated retry with 90s delays between crates

---

## Milestone v0.5.0 â€” Dialects & Optimizations (Q1 2026)

### Objectives

* Add a safe, explicit knob for ODO bounds across COBOL dialects; squeeze throughput without changing outputs.

### Deliverables

1. **Dialect lever** (#51)

   * Config:

     ```toml
     [parser]
     occurs_fixed_with_depends_lower_bound = "n"   # allowed: "n" | "0" | "1"; default "n"
     ```
   * CLI flag and env var mapping (`--dialect-odo-lower-bound`, `COPYBOOK_DIALECT_ODO_LOWER`)
   * Golden fixtures for each setting; docs examples and migration notes
2. **Perf tune (SIMD/I/O)**

   * Target +10â€“20% p95 throughput maintained under budgets; no API/behavior changes

### Exit Criteria

* Same inputs under each dialect mode produce **documented** and **tested** outcomes
* No regressions vs v0.3.0 budgets; CI receipts show deltas â‰¤ 5% except where improved
* Default behavior unchanged (back-compat preserved)

### Risks & Mitigations

* **Behavior drift for existing users** â†’ default remains current `"n"`; strong docs + examples

---

## Toward v1.0.0 â€” Stability & Ecosystem (Q2 2026)

### Objectives

* Lock public behaviors, add first-class connectors.

### Deliverables

* **API freeze window** (4 weeks): only doc/bench/test changes
* **Ecosystem adapters** (best-effort): Arrow/Parquet writer crate prototype, Kafka example pipeline
* **Support policy**: 6-month minor support window; security patches anytime

### Exit Criteria

* Changelog & README carry a "**Stability Guarantees**" section
* Example integrations build in CI; round-trip and perf budgets still satisfied

---

## Project board & labels

* **Board columns**: Backlog â†’ In Progress â†’ In Review â†’ Bench Verified â†’ Done
* **Labels**: `area:parser`, `area:bench`, `area:docs`, `type:feature`, `type:bug`, `type:tests`, `perf:budget-regression`
* **Rules**:

  * Anything touching hot paths must pass **Bench Verified** before **Done**
  * Any PR adding perf numbers must **not** repeat themâ€”link to canonical section

---

## Release train

* **Minor**: every 6â€“8 weeks (feature batches)
* **Patch**: as-needed (bug or doc only)
* **Pre-release checklist**: `cargo build -r` â€¢ `nextest` â€¢ `bench receipts` â€¢ link check â€¢ changelog â€¢ tag â€¢ GitHub release

---

## Owner matrix (example; edit as you like)

| Area              | DRI        | Backup     |
| ----------------- | ---------- | ---------- |
| Parser & dialects | @you       | @contrib-A |
| Codec & perf      | @you       | @contrib-B |
| CLI & docs        | @contrib-C | @you       |
| CI/bench receipts | @contrib-D | @contrib-C |

---

## Paste-ready CI snippets

**Bench receipts (GitHub Actions)**

```yaml
- name: Run benches
  run: PERF=1 cargo bench -p copybook-bench -- --output-format bencher | tee bench.out

- name: Roll up perf JSON
  run: |
    python - << 'PY'
    import json,glob,os,sys
    from pathlib import Path
    reports=list(glob.glob('target/criterion/**/new/benchmark.json',recursive=True))
    out={"display_gibs":None,"comp3_mibs":None}
    # TODO: parse actual metric keys; set SLOs
    Path('perf.json').write_text(json.dumps(out))
    PY

- name: Upload artifacts
  uses: actions/upload-artifact@v4
  with:
    name: bench-artifacts
    path: |
      perf.json
      target/criterion/**
    retention-days: 14

- name: Comment perf summary
  if: ${{ github.event_name == 'pull_request' }}
  run: gh pr comment ${{ github.event.pull_request.number }} --body "$(cat perf.json)"
```

**SLO gate (simple)**

```yaml
- name: Enforce SLOs
  run: |
    python - << 'PY'
    import json,sys
    d=json.load(open('perf.json'))
    assert d["display_gibs"] >= 4.1, "DISPLAY throughput below 4.1 GiB/s"
    assert d["comp3_mibs"] >= 560, "COMP-3 throughput below 560 MiB/s"
    PY
```

---

## Definition of Done (all milestones)

* âœ… Tests green (unit/integration/goldens)
* âœ… Bench receipts uploaded; budgets respected
* âœ… Docs updated (no duplicated performance figures)
* âœ… Changelog entry & tag created